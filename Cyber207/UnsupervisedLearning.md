# Unsupervised Learning: k-Means and PCA

* Agenda
  - Announcements
  - Questions about async sessions
  - Regularization
  - Feed Forward Neural Networks

## Part 1.

* Regularization
  - Ridge Regression
  - Î» x slope2
  - Size = y_intercept + (slope1 x feature1) + (slope2 x feature2)
  - LASSO Regression
  - Elastic-net regression

## Part 2.

* [A Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=5,4&seed=0.56015&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false)

* Linear function
  - A linear function in machine learning is a model that tries to find a straight line (or hyperplane in higher dimensions) that best represents the relationship between input features (independent variables) and the target variable (dependent variable). 

* Tanh function
  - The tanh function, or hyperbolic tangent, is a crucial activation function in machine learning, particularly in neural networks, that maps input values to a range between -1 and 1, offering advantages like zero-centeredness and potentially faster convergence compared to sigmoid.

* neuron
  - refers to a fundamental processing unit, inspired by biological neurons in the brain, that receives inputs, processes them, and generates an output. 

## Class Supporting Video

6.1 Classification Metrics

6.2 Multiclass Classification

6.3 Multiclass Loss

6.4 Network Graphs

6.5 Linear Model Limitations

6.6 Digit Classification History
