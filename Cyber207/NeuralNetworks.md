# Feedforward Neural Networks

* Agenda
  - Neural Networks
  - PCA

## Part 1.

* [A Neural Network Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=5,4&seed=0.56015&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=true&cosY=false&sinY=true&collectStats=false&problem=classification&initZero=false&hideText=false)

* [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)

* Latent Space Representation
  - A lower-dimensional, abstract representation of data that captures the underlying structure and patterns, often used for tasks like dimensionality reduction, clustering, and generative modeling.

* Matrix notation
  - Provides a concise and efficient way to represent data, model parameters, and operations, particularly for algorithms involving linear algebra, such as linear regression and neural networks.
 
## Part 2.

* RELU = Rectified Linear Unit
* Dropout
* Convolutional layer
  - A fundamental building block of Convolutional Neural Networks (CNNs), particularly used for image and video analysis, where it applies a convolution operation to the input, using a learned filter (or kernel) to extract features and create a feature map.
  
W9 -Convolutional Neural Network.ipynb

## Class Supporting Video

8.1 XOR Problem

8.2 Beyond XOR

8.3 Back Propogation I

8.4 Back Propogation II

8.5 Neural Network Details

8.6 Biological Inspiration
